from pyspark.sql import DataFrame
from pyspark.sql.functions import coalesce, col

def process_flattened_df_with_select_distinct(df: DataFrame, ss_columns: list, df_name: str = "", key_col: str = "stg_business_entity_id") -> DataFrame:
    """
    Optimized version using select + distinct
    """
    df = df.select(ss_columns).distinct().coalesce(10)
    processing_columns = [c for c in ss_columns if c != key_col]

    return (
        df
        .select(processing_columns)  # Early column pruning - KEY OPTIMIZATION
        .withColumn("_any_not_null", coalesce(*[col(c) for c in processing_columns]))
        .filter(col("_any_not_null").isNotNull())
        .drop("_any_not_null")
        .select(ss_columns)  # Final column selection (adds back key_col if needed)
        .distinct()          # Distinct on smaller dataset
        .coalesce(20)
    )

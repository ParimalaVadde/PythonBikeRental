# Get expected columns (excluding business entity id)
expected_revenue_columns = [col for col in ss.revenue if col != "stg_business_entity_id"]

# For small datasets, coalesce to single partition to reduce overhead
transformed_json_df = transformed_json_df.coalesce(1)

# Step 1: Add ALL missing columns in single operation using select
existing_columns = set(transformed_json_df.columns)
missing_columns = [col_name for col_name in expected_revenue_columns 
                  if col_name not in existing_columns]

# Build select expression with missing columns added
select_expressions = []
for col_name in ss.revenue:
    if col_name in existing_columns:
        select_expressions.append(col(col_name))
    else:
        print(f"Adding missing column: {col_name}")
        dtype = (
            "date" if "date" in col_name
            else "double" if "amount" in col_name  
            else "string"
        )
        select_expressions.append(lit(None).cast(dtype).alias(col_name))

# Step 2: Single operation - select with missing columns + rename + filter + distinct
revenue_value_columns = ["end_date" if c == "card_revenue__end_date" else c 
                        for c in expected_revenue_columns]

# Build non-null condition using coalesce (most efficient for small data)
non_null_condition = coalesce(*[col(c) for c in revenue_value_columns]).isNotNull()

# Single-pass operation combining everything
transformed_revenue = (transformed_json_df
                      .select(*select_expressions)
                      .withColumnRenamed("card_revenue__end_date", "end_date")  
                      .filter(non_null_condition)
                      .distinct())

def relationship(transformed_business_entity,ss, transformed_df,compute_uuid_udf):
    
    # Process vendor contacts - ONLY if vendor_contact_name is not null
    vendor_contacts_raw = transformed_df.select(*ss.vendor_contact).distinct()
    vendor_contacts_filtered = vendor_contacts_raw.filter(col("vendor_contact_name").isNotNull())
    
    
    vendor_contacts_final = vendor_contacts_filtered.select(
    	col("stg_business_entity_id"),
    	col("vendor_contact_name").alias("contact_name"),
    	lit(None).cast("string").alias("contact_title")
    )
    
    
    # Only keep contacts that actually have contact names
    transformed_contacts = vendor_contacts_final.filter(col("contact_name").isNotNull())
    
    transformed_contacts = transformed_contacts.withColumn(
    "is_active", 
    lit(True)  # This creates a Boolean column with True values for all rows
    )
    
    # Generate UUIDs only for valid contacts
    if transformed_contacts.count() > 0:
        transformed_contacts = transformed_contacts.dropDuplicates()
        transformed_contacts = transformed_contacts.withColumn(
            "business_entity_contact_id",
            compute_uuid_udf(struct(*transformed_contacts.columns))
        )
    else:
        # Ensure schema compatibility: add empty columns
        transformed_contacts = vendor_contacts_raw.select(
            col("stg_business_entity_id"),
            lit(None).cast("string").alias("contact_name"),
            lit(None).cast("string").alias("contact_title"),
            lit(True).cast("boolean").alias("is_active"),
            lit(None).cast("string").alias("business_entity_contact_id")
        ).limit(0)   # makes it empty but with schema
    
    # # Get vendor contact names from transformed_df
    # vendor_names_df = transformed_df.select(
    #     col("stg_business_entity_id"),
    #     col("vendor_contact_name").alias("contact_name")
    # ).distinct()

    # Joining this with transformed_contacts to get the accurate business_entity_contact_id
    preferred_contacts = transformed_contacts.select("stg_business_entity_id", "contact_name", "business_entity_contact_id")
        
    
    # Print column names for debugging
    print("transformed_business_entity columns:", transformed_business_entity.columns)
    print("transformed_df columns:", transformed_df.columns)

    # Create a mapping from client_name to stg_business_entity_id using business_entity_details
    client_mapping = transformed_business_entity.select(
        col("business_entity_name").alias("client_name"),
        col("stg_business_entity_id").alias("client_stg_business_entity_id")
    )
    

    # Initialize list to collect all relationship DataFrames
    relationship_dfs = []
    
    # 1. Create client -> firm relationships first (for distinct clients)
    # Filter out empty/null stg_business_entity_id and join with transformed_df to get required columns
    distinct_clients = transformed_df.select(
        "client_name", 
        "stg_business_entity_id",
        "client_vendor_id",
        "client_vendor_site_id", 
        "client_ecid",
        "supplier_ecid"
    ).filter(
        col("client_name").isNotNull() & 
        (col("client_name") != "") &
        col("stg_business_entity_id").isNotNull() & 
        (col("stg_business_entity_id") != "") &
        (col("stg_business_entity_id") != "null") &
        (col("stg_business_entity_id") != "none")
    ).distinct()
    
    client_firm_df = distinct_clients.join(
        client_mapping,
        on="client_name",
        how="inner"
    ).select(
        col("client_stg_business_entity_id").alias("stg_business_entity_id"),
        lit(None).alias("business_entity_contact_id"),
        lit("2d35a04a-5fdf-50d5-7750-c1c7621ddc33").alias("stg_related_business_entity_id"),
        lit(None).alias("related_business_entity_contact_id"),
        lit("client").alias("business_entity_role"),
        lit("firm").alias("related_business_entity_role"),
        lit(None).alias("client_vendor_id"),
        lit(None).alias("client_vendor_site_id"),
        lit(None).alias("client_ecid"),
        lit(None).alias("supplier_ecid")
    )
    
    relationship_dfs.append(client_firm_df)
    
    # 2. Create supplier -> client relationships
    # Filter out empty/null stg_business_entity_id
    # Alias the dataframes before join
    df = transformed_df.alias("df")
    pc = preferred_contacts.alias("pc")
    
    supplier_client_base = df.filter(
        col("df.stg_business_entity_id").isNotNull() & 
        (col("df.stg_business_entity_id") != "") & 
        (col("df.stg_business_entity_id") != "null") & 
        (col("df.stg_business_entity_id") != "none")
    ).join(
        client_mapping.alias("cm"),
        df["client_name"] == col("cm.client_name"),
        how="inner"
    ).join(
        pc,
        (df["stg_business_entity_id"] == pc["stg_business_entity_id"]) &
        (df["vendor_contact_name"] == pc["contact_name"]),
        how="left"
    )
    
    supplier_client_df = supplier_client_base.select(
        df["stg_business_entity_id"],
        pc["business_entity_contact_id"],
        col("cm.client_stg_business_entity_id").alias("stg_related_business_entity_id"),
        lit(None).alias("related_business_entity_contact_id"),
        lit("supplier").alias("business_entity_role"),
        lit("buyer").alias("related_business_entity_role"),
        df["client_vendor_id"],
        df["client_vendor_site_id"],
        df["client_ecid"],
        df["supplier_ecid"]
    )
    
    relationship_dfs.append(supplier_client_df)
    
    # 3. Create supplier -> firm relationships (only when supplier_ecid is not null/empty)
    supplier_firm_base = transformed_df.filter(
        col("supplier_ecid").isNotNull() & 
        (col("supplier_ecid") != "") & 
        (col("supplier_ecid") != "NULL") &
        col("stg_business_entity_id").isNotNull() & 
        (col("stg_business_entity_id") != "") &
        (col("stg_business_entity_id") != "null") &
        (col("stg_business_entity_id") != "none")
    ).join(
        preferred_contacts,
        on="stg_business_entity_id",
        how="left"
    )
    
    supplier_firm_df = supplier_firm_base.select(
        col("stg_business_entity_id"),
        lit(None).alias("business_entity_contact_id"),
        lit("2d35a04a-5fdf-50d5-7750-c1c7621ddc33").alias("stg_related_business_entity_id"),
        lit(None).alias("related_business_entity_contact_id"),
        lit("client").alias("business_entity_role"),
        lit("firm").alias("related_business_entity_role"),
        col("client_vendor_id"),
        col("client_vendor_site_id"),
        col("client_ecid"),
        col("supplier_ecid")
    )

    relationship_dfs.append(supplier_firm_df)
    
    # Union all relationship DataFrames
    union_df = relationship_dfs[0]
    for df in relationship_dfs[1:]:
        union_df = union_df.union(df)
    
    # Drop duplicates
    union_df = union_df.dropDuplicates()


    return union_df
    
    


# Call the `relationship` function and assign the result to `transformed_relationship`
transformed_relationship = relationship(transformed_business_entity_details, ss, transformed_df,compute_uuid_udf)

transformed_relationship = transformed_relationship.withColumn(
    "is_active", 
    lit(True)  # This creates a Boolean column with True values for all rows
)


# Remove the line that renames "related_business_entity_id" since it doesn't exist in our schema
# transformed_relationship = transformed_relationship.withColumnRenamed("related_business_entity_id", "stg_related_business_entity_id")

# Check for void data types before proceeding
print("Data types in transformed_relationship:")
for col_name, col_type in transformed_relationship.dtypes:
    print(f"{col_name}: {col_type}")


# Find columns with void data type
void_columns = [col_name for col_name, col_type in transformed_relationship.dtypes if col_type == 'void']
print(f"Void columns found: {void_columns}")


if void_columns:
    print(f"Fixing void columns: {void_columns}")
    for void_col in void_columns:
        transformed_relationship = transformed_relationship.withColumn(
            void_col, 
            lit(None).cast(StringType())  # Cast void to nullable string
        )

# Generate UUID for business_entity_relationship_id
transformed_relationship_columns = [
    col for col in transformed_relationship.columns 
    if col not in ['client_ecid', 'client_vendor_id', 'client_vendor_site_id', 'supplier_ecid']
]

transformed_relationship = transformed_relationship.withColumn(
    "business_entity_relationship_id",
    compute_uuid_udf(struct(*[col(c) for c in transformed_relationship_columns]))
)

def write_single_csv_to_s3_fixed(df: DataFrame, s3_bucket: str, s3_key: str, temp_path: str):
    """
    Writes a Spark DataFrame as a single CSV file with proper escaping to S3.
    Handles void data type columns by converting them to string type.
    """
    
    # Check for void columns and convert them to string type
    void_columns = [field.name for field in df.schema.fields if isinstance(field.dataType, NullType)]
    
    if void_columns:
        print(f"Found void columns: {void_columns}. Converting to string type.")
        # Convert void columns to string type with null values
        for col_name in void_columns:
            df = df.withColumn(col_name, lit(None).cast("string"))
    
    try:
        # Ensure temp_path ends with a trailing slash
        if not temp_path.endswith('/'):
            temp_path += '/'
        
        # Coalesce to one partition and write to temp S3 directory with proper CSV options
        df.coalesce(1).write.mode("overwrite") \
            .option("header", "true") \
            .option("quote", '"') \
            .option("escape", '"') \
            .option("quoteAll", "true") \
            .option("multiLine", "true") \
            .option("timestampFormat", "yyyy-MM-dd HH:mm:ss") \
            .option("dateFormat", "yyyy-MM-dd") \
            .csv(temp_path)
        
        # Initialize S3 client
        s3 = boto3.client("s3")
        
        # Parse temp path
        temp_bucket = temp_path.replace("s3://", "").split("/")[0]
        temp_prefix = "/".join(temp_path.replace("s3://", "").split("/")[1:])
        
        # Remove trailing slash from prefix if present
        if temp_prefix.endswith('/'):
            temp_prefix = temp_prefix[:-1]
        
        # List objects in temp directory
        response = s3.list_objects_v2(Bucket=temp_bucket, Prefix=temp_prefix)
        
        if 'Contents' not in response:
            raise Exception(f"No files found in temp path: {temp_path}")
        
        objects = response['Contents']
        
        # Find the CSV part file, excluding _SUCCESS and other metadata files
        csv_files = [
            obj['Key'] for obj in objects 
            if obj['Key'].endswith(".csv") and not obj['Key'].endswith("_SUCCESS")
        ]
        
        if not csv_files:
            raise Exception(f"No CSV files found in temp directory: {temp_path}")
        
        # Use the first (and should be only) CSV file
        part_file = csv_files[0]
        
        # Copy the CSV file to the target location
        s3.copy_object(
            Bucket=s3_bucket,
            CopySource={'Bucket': temp_bucket, 'Key': part_file},
            Key=s3_key
        )
        
        print(f"Successfully copied CSV to s3://{s3_bucket}/{s3_key}")
        
        # Clean up temp files - delete all objects in the temp directory
        delete_objects = [{'Key': obj['Key']} for obj in objects]
        if delete_objects:
            s3.delete_objects(
                Bucket=temp_bucket,
                Delete={'Objects': delete_objects}
            )
            print(f"Cleaned up {len(delete_objects)} temp files")
            
    except Exception as e:
        print(f"Error in write_single_csv_to_s3_fixed: {str(e)}")
        raise
    

write_single_csv_to_s3_fixed(
    transformed_relationship,
    s3_bucket="app-id-111597-dep-id-114116-uu-id-9x0jt94siuto",
    s3_key="pfd_scripts/pfd_staging_pvr_test/transformed_relationship.csv",
    temp_path="s3://app-id-111597-dep-id-114116-uu-id-9x0jt94siuto/upsert/pfd_staging/_tmp"
)


# transformed_relationship = transformed_relationship.withColumn(
#     "business_entity_relationship_id",
#     compute_uuid_udf(struct(*transformed_relationship.columns))
# )

# Show distinct rows in the resulting DataFrame
transformed_relationship.distinct().show(truncate=False)

# # Select and rename columns from `transformed_relationship`
# transformed_rel_identifiers = (transformed_relationship
#     .select(
#         col("stg_business_entity_id"),
#         col("business_entity_relationship_id"),
#         col("client_vendor_id"),
#         col("client_vendor_site_id"),
#         #col("client_ecid"),
#         col("supplier_ecid"),
#         col("business_entity_role"),
#         col("related_business_entity_role")
#     )
#     .filter(
#         ~((col("business_entity_role") == "client") & 
#           (col("related_business_entity_role") == "firm"))
#     )
#     .select(
#         col("stg_business_entity_id"),
#         col("business_entity_relationship_id"),
#         col("client_vendor_id"),
#         col("client_vendor_site_id"),
#         #col("client_ecid"),
#         col("supplier_ecid")
#     )
# )


# Create dataset for client-firm relationships
client_firm_data = (transformed_relationship
    .filter(
        (col("business_entity_role") == "client") & 
        (col("related_business_entity_role") == "firm")
    )
    .select(
        col("stg_business_entity_id"),
        col("business_entity_contact_id"),
        col("stg_related_business_entity_id"),
        col("related_business_entity_contact_id"),
        col("business_entity_role"),
        col("related_business_entity_role"),
        col("client_vendor_id"),
        col("client_vendor_site_id"),
        col("is_active"),
        col("business_entity_relationship_id"),
        lit(None).cast("string").alias("supplier_ecid")  # Add null supplier_ecid for union compatibility
    )
)

# Create dataset for supplier-buyer relationships
supplier_buyer_data = (transformed_relationship
    .filter(
        (col("business_entity_role") == "supplier") & 
        (col("related_business_entity_role") == "buyer")
    )
    .select(
        col("stg_business_entity_id"),
        col("business_entity_contact_id"),
        col("stg_related_business_entity_id"),
        col("related_business_entity_contact_id"),
        col("business_entity_role"),
        col("related_business_entity_role"),
        lit(None).cast("string").alias("client_vendor_id"),      # Add null client_vendor_id for union compatibility
        lit(None).cast("string").alias("client_vendor_site_id"), # Add null client_vendor_site_id for union compatibility
        col("is_active"),
        col("business_entity_relationship_id"),
        col("supplier_ecid")
    )
)

# Union both datasets
transformed_rel_identifiers = client_firm_data.union(supplier_buyer_data)

# List of columns to melt for `transformed_rel_identifiers`
transformed_rel_identifiers_columns = ["client_vendor_id", "client_vendor_site_id","supplier_ecid"]


# Melt `transformed_rel_identifiers` using the `melt_dataframe` function
transformed_rel_identifiers_v1 = utl.melt_dataframe(
    transformed_rel_identifiers,
    id_column="business_entity_relationship_id",
    columns_to_melt=transformed_rel_identifiers_columns,
    melted_column_names=("identifier_type", "identifier_value")
)

transformed_df_iden1 = (transformed_df.select("stg_payor_business_entity_id","client_ecid")
                    .distinct()
                      )

# Join to get business_entity_relationship_id where stg_business_entity_id matches stg_payor_business_entity_id
transformed_df_iden = transformed_df_iden1.join(
    transformed_relationship.select("stg_business_entity_id", "business_entity_relationship_id"),
    col("stg_payor_business_entity_id") == col("stg_business_entity_id"),
    how="inner"
).select(
    col("business_entity_relationship_id"),
    col("client_ecid")
)
                    
                    
transformed_rel_identifiers_v2 = utl.melt_dataframe(
    transformed_df_iden,
    id_column="business_entity_relationship_id",
    columns_to_melt=["client_ecid"],
    melted_column_names=("identifier_type", "identifier_value")
)

# Fix: Use proper union syntax
transformed_rel_identifiers = transformed_rel_identifiers_v1.union(transformed_rel_identifiers_v2)
transformed_rel_identifiers = transformed_rel_identifiers.dropDuplicates()

# Perform a left join between `transformed_identifiers` and `transformed_rel_identifiers`
transformed_rel_identifiers = transformed_rel_identifiers.join(
    transformed_relationship,
    on="business_entity_relationship_id",  # Use the common column for the join
    how="left"
)

transformed_rel_identifiers = transformed_rel_identifiers.select(
    col("identifier_type"),
    col("identifier_value"),
    col("business_entity_relationship_id").alias("related_identifier")).withColumn("related_identifier_source", lit("relationship"))

 
#transformed_rel_identifiers.show(truncate=False)

relationship_key_pairs = transformed_rel_identifiers.select(
    "identifier_type", "identifier_value"
).distinct()

# identifiers_list = [col for col in ss.identifiers if col != 'client_ecid']
# transformed_identifiers_columns_list = [col for col in ss.transformed_identifiers_columns if col != 'client_ecid']

# Select columns from `transformed_df` for `transformed_identifiers`
transformed_identifiers = transformed_df.select(*ss.identifiers)

# Melt `transformed_identifiers` using the `melt_dataframe` function
melted_business_identifiers = utl.melt_dataframe(
    transformed_identifiers,
    id_column="stg_business_entity_id",
    columns_to_melt=ss.transformed_identifiers_columns,
    melted_column_names=("identifier_type", "identifier_value")
)


melted_business_identifiers = melted_business_identifiers.dropDuplicates()

#Apply Anti-join using only identifier_type + identifier_value
filtered_business_identifiers = melted_business_identifiers.alias("biz").join(
    broadcast(relationship_key_pairs).alias("rel"),
    on=[
        col("biz.identifier_type") == col("rel.identifier_type"),
        col("biz.identifier_value") == col("rel.identifier_value")
    ],
    how="left_anti"
)

# Final selection with source
transformed_identifiers = filtered_business_identifiers.select(
    col("identifier_type"),
    col("identifier_value"),
    col("stg_business_entity_id").alias("related_identifier")
).withColumn("related_identifier_source", lit("business_entity"))


#transformed_identifiers.show(truncate=False)


# # Perform a left join between `transformed_identifiers` and `transformed_rel_identifiers`
# transformed_identifiers = transformed_identifiers.join(
#     transformed_rel_identifiers,
#     on="stg_business_entity_id",  # Use the common column for the join
#     how="left"
# # 

transformed_identifiers = transformed_identifiers.union(transformed_rel_identifiers)

# Drop duplicates
transformed_identifiers = transformed_identifiers.dropDuplicates()

transformed_identifiers = transformed_identifiers.filter(
    col("identifier_value").isNotNull()
)

# Update identifier_type column in transformed_identifiers
transformed_identifiers = transformed_identifiers.withColumn(
    "identifier_type",
    when(col("identifier_type") == "client_ecid", "ecid")
    .when(col("identifier_type") == "supplier_ecid", "ecid")
    .otherwise(col("identifier_type"))
)

transformed_identifiers = transformed_identifiers.withColumn(
    "is_active", 
    lit(True)  # This creates a Boolean column with True values for all rows
)


transformed_identifiers = transformed_identifiers.withColumn(
    "identifier_id",
    compute_uuid_udf(struct(*transformed_identifiers.columns))
)

# Show the resulting DataFrame
transformed_identifiers.show(truncate=False)

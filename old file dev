in staging_schema.py

card_revenue_schema = ArrayType(StructType([
    StructField("end_date", StringType(), True),
    StructField("1m", StructType([
        StructField("start_date", StringType(), True),
        StructField("average_monthly_amount", DoubleType(), True)
    ])),
    StructField("3m", StructType([
        StructField("start_date", StringType(), True),
        StructField("average_monthly_amount", DoubleType(), True)
    ])),
    StructField("12m", StructType([
        StructField("start_date", StringType(), True),
        StructField("average_monthly_amount", DoubleType(), True)
    ]))
]))


revenue = ["stg_business_entity_id", "card_revenue__end_date", "card_revenue__1m__start_date", "card_revenue__1m__average_monthly_amount", "card_revenue__3m__start_date", "card_revenue__3m__average_monthly_amount", "card_revenue__12m__start_date", "card_revenue__12m__average_monthly_amount"]


in utils.py

def flatten_nested_json_column(df, column_name, schema, explode_array=True):
    """
    Flattens a nested JSON column in a PySpark DataFrame.
    
    Args:
        df (DataFrame): The input PySpark DataFrame.
        column_name (str): The name of the JSON column to flatten.
        schema (StructType): The schema of the JSON column.
        explode_array (bool): Whether to explode arrays or join with semicolon.
    
    Returns:
        DataFrame: The DataFrame with the flattened JSON column.
    """
    try:
        # NEW: Check if the column exists and has any non-null values
        if column_name not in df.columns:
            print(f"Column {column_name} does not exist in DataFrame")
            return df
            
        # NEW: Check if all values in the column are null
        non_null_count = df.filter(col(column_name).isNotNull()).count()
        
        if non_null_count == 0:
            print(f"Column {column_name} contains only null values, skipping flattening")
            # Just return the dataframe as-is, keeping the null column
            return df
        
        # Parse the JSON column into structured data
        df = df.withColumn(column_name, from_json(col(column_name), schema))
        
        # If explode_array is False, join array elements with semicolon
        if not explode_array:
            df = df.withColumn(column_name, concat_ws(";", col(column_name)))
            return df
        
        # Explode the array to create one row per element
        df = df.withColumn(column_name, explode(col(column_name)))
        # Iterate over the fields in the schema
        for field in schema.elementType.fields:  # Use `elementType` for ArrayType
            field_name = field.name
            field_type = field.dataType
            # If the field is a nested struct, recursively flatten it
            if isinstance(field_type, StructType):
                for nested_field in field_type.fields:
                    nested_field_name = nested_field.name
                    df = df.withColumn(
                        f"{column_name}__{field_name}__{nested_field_name}",
                        col(f"{column_name}.{field_name}.{nested_field_name}")
                    )
            else:
                # If the field is not nested, extract it directly
                df = df.withColumn(f"{column_name}__{field_name}", col(f"{column_name}.{field_name}"))
        # Drop the original JSON column
        df = df.drop(column_name)
    except Exception as error:
        print(f"Error flattening column {column_name}: {error}")
    return df
	

in pfd_staging.py


# Flatten the JSON columns
transformed_json_df = transformed_df.select(*ss.jsoncol)
 
# Flatten nested JSON columns
for column, schema in [
        ("card_revenue", ss.card_revenue_schema),
        ("card_transactions_stability", ss.card_transactions_stability),
        ("associated_people", ss.associated_people_schema),
        ("industries", ss.industries_schema), 
        #("company_structure", ss.company_structure_schema),  
        ("technologies", ss.technologies_schema),
    ]:
        transformed_json_df = utl.flatten_nested_json_column(transformed_json_df, column, schema)
		
		
		
		
in input pfd_analysis file . we have following records

card_revenue
NULL
{'end_date': '2025-03-31', 'date_accessible': '2025-06-15', '1m': {'start_date': '2025-03-01', 'average_monthly_amount': None}, '3m': {'start_date': '2025-01-01', 'average_monthly_amount': None}, '12m': {'start_date': '2024-04-01', 'average_monthly_amount': None}}
{'end_date': '2025-03-31', 'date_accessible': '2025-06-15', '1m': {'start_date': '2025-03-01', 'average_monthly_amount': 8815233.7777}, '3m': {'start_date': '2025-01-01', 'average_monthly_amount': 8310170.7713}, '12m': {'start_date': '2024-04-01', 'average_monthly_amount': 7844672.1036}}
{'end_date': '2025-03-31', 'date_accessible': '2025-06-15', '1m': {'start_date': '2025-03-01', 'average_monthly_amount': 6767731.4118}, '3m': {'start_date': '2025-01-01', 'average_monthly_amount': 5545336.8131}, '12m': {'start_date': '2024-04-01', 'average_monthly_amount': 5226886.2024}}
{'end_date': '2025-03-31', 'date_accessible': '2025-06-15', '1m': {'start_date': '2025-03-01', 'average_monthly_amount': 167570.2109}, '3m': {'start_date': '2025-01-01', 'average_monthly_amount': 179786.4464}, '12m': {'start_date': '2024-04-01', 'average_monthly_amount': 194118.9216}}


only these 2 records are loading
{'end_date': '2025-03-31', 'date_accessible': '2025-06-15', '1m': {'start_date': '2025-03-01', 'average_monthly_amount': 8815233.7777}, '3m': {'start_date': '2025-01-01', 'average_monthly_amount': 8310170.7713}, '12m': {'start_date': '2024-04-01', 'average_monthly_amount': 7844672.1036}}
{'end_date': '2025-03-31', 'date_accessible': '2025-06-15', '1m': {'start_date': '2025-03-01', 'average_monthly_amount': 6767731.4118}, '3m': {'start_date': '2025-01-01', 'average_monthly_amount': 5545336.8131}, '12m': {'start_date': '2024-04-01', 'average_monthly_amount': 5226886.2024}}


1st and last records are not getting loaded.
may i know the reason

# OPTIMIZED VERSION - Key improvements for performance

from pyspark.sql.functions import *
from pyspark.sql import functions as F

# 1. CACHE intermediate DataFrames that are used multiple times
transformed_relationship = transformed_relationship.cache()
transformed_df = transformed_df.cache()

# 2. Select and rename columns from `transformed_relationship`
transformed_rel_identifiers = transformed_relationship.select(
    col("stg_business_entity_id"),
    col("business_entity_relationship_id"),
    col("client_vendor_id"),
    col("client_vendor_site_id"),
    col("client_ecid"),
    col("supplier_ecid"),
    col("associated_tax_ids")
)

# 3. List of columns to melt for `transformed_rel_identifiers`
transformed_rel_identifiers_columns = ["client_vendor_id", "client_vendor_site_id", "client_ecid","supplier_ecid","associated_tax_ids"]

# 4. Melt `transformed_rel_identifiers` using the `melt_dataframe` function
transformed_rel_identifiers = utl.melt_dataframe(
    transformed_rel_identifiers,
    id_column="business_entity_relationship_id",
    columns_to_melt=transformed_rel_identifiers_columns,
    melted_column_names=("identifier_type", "identifier_value")
)

# 5. OPTIMIZATION: Filter out null values early and cache
transformed_rel_identifiers = transformed_rel_identifiers.filter(
    col("identifier_value").isNotNull()
).cache()

# 6. Inner join (no change needed here as it's already optimal)
transformed_rel_identifiers = transformed_rel_identifiers.join(
    transformed_relationship,
    on="business_entity_relationship_id",
    how="inner"
)

# 7. Select and add source column with optimized identifier_type transformation
transformed_rel_identifiers = transformed_rel_identifiers.select(
    # OPTIMIZATION: Apply identifier_type transformation here instead of later
    when(col("identifier_type") == "client_ecid", "ecid")
    .when(col("identifier_type") == "supplier_ecid", "ecid")
    .otherwise(col("identifier_type")).alias("identifier_type"),
    col("identifier_value"),
    col("business_entity_relationship_id").alias("related_identifier")
).withColumn("related_identifier_source", lit("relationship"))

# 8. OPTIMIZATION: Create relationship key pairs with early caching and coalescing
relationship_key_pairs = transformed_rel_identifiers.select(
    "identifier_type", "identifier_value"
).distinct().coalesce(1).cache()  # Coalesce to reduce partitions for broadcast

# 9. Select columns from `transformed_df` for `transformed_identifiers`
transformed_identifiers = transformed_df.select(*ss.identifiers)

# 10. Melt `transformed_identifiers` using the `melt_dataframe` function
melted_business_identifiers = utl.melt_dataframe(
    transformed_identifiers,
    id_column="stg_business_entity_id",
    columns_to_melt=ss.transformed_identifiers_columns,
    melted_column_names=("identifier_type", "identifier_value")
)

# 11. OPTIMIZATION: Filter nulls early and cache
melted_business_identifiers = melted_business_identifiers.filter(
    col("identifier_value").isNotNull()
).cache()

# 12. OPTIMIZATION: Use broadcast hint explicitly and smaller broadcast DataFrame
filtered_business_identifiers = melted_business_identifiers.alias("biz").join(
    broadcast(relationship_key_pairs).alias("rel"),
    on=[
        col("biz.identifier_type") == col("rel.identifier_type"),
        col("biz.identifier_value") == col("rel.identifier_value")
    ],
    how="left_anti"
)

# 13. Final selection with source and identifier_type transformation
transformed_identifiers = filtered_business_identifiers.select(
    # OPTIMIZATION: Apply identifier_type transformation here
    when(col("identifier_type") == "client_ecid", "ecid")
    .when(col("identifier_type") == "supplier_ecid", "ecid")
    .otherwise(col("identifier_type")).alias("identifier_type"),
    col("identifier_value"),
    col("stg_business_entity_id").alias("related_identifier")
).withColumn("related_identifier_source", lit("business_entity"))

# 14. OPTIMIZATION: Union and apply all transformations in single pass
transformed_identifiers = transformed_identifiers.union(transformed_rel_identifiers).select(
    col("identifier_type"),
    col("identifier_value"), 
    col("related_identifier"),
    col("related_identifier_source"),
    lit(True).alias("is_active"),  # Add is_active column here
    compute_uuid_udf(struct(
        col("identifier_type"),
        col("identifier_value"),
        col("related_identifier"), 
        col("related_identifier_source"),
        lit(True)  # Include is_active in UUID computation
    )).alias("identifier_id")
)

# 15. OPTIMIZATION: Single dropDuplicates call at the end with coalesce
transformed_identifiers = transformed_identifiers.dropDuplicates().coalesce(200)

# 16. Show the resulting DataFrame
transformed_identifiers.show(truncate=False)

# CLEANUP: Unpersist cached DataFrames to free memory
transformed_relationship.unpersist()
transformed_df.unpersist()
transformed_rel_identifiers.unpersist()
relationship_key_pairs.unpersist()
melted_business_identifiers.unpersist()

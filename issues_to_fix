import sys
import boto3
import json
import pandas as pd
# from pyspark.sql.types import StructType, StructField, StringType, ArrayType, DoubleType, IntegerType, MapType


def flatten_nested_json_column(df, column_name, schema, explode_array=True):
    """
    Flattens a nested JSON column in a PySpark DataFrame.
    
    Args:
        df (DataFrame): The input PySpark DataFrame.
        column_name (str): The name of the JSON column to flatten.
        schema (StructType): The schema of the JSON column.
        explode_array (bool): Whether to explode arrays or join with semicolon.
    
    Returns:
        DataFrame: The DataFrame with the flattened JSON column.
    """
    try:
        # NEW: Check if the column exists and has any non-null values
        if column_name not in df.columns:
            print(f"Column {column_name} does not exist in DataFrame")
            return df
            
        # NEW: Check if all values in the column are null
        non_null_count = df.filter(col(column_name).isNotNull()).count()
        
        if non_null_count == 0:
            print(f"Column {column_name} contains only null values, skipping flattening")
            # Just return the dataframe as-is, keeping the null column
            return df
        
        # Parse the JSON column into structured data
        df = df.withColumn(column_name, from_json(col(column_name), schema))
        
        # If explode_array is False, join array elements with semicolon
        if not explode_array:
            df = df.withColumn(column_name, concat_ws(";", col(column_name)))
            return df
        
        # Explode the array to create one row per element
        df = df.withColumn(column_name, explode(col(column_name)))
        # Iterate over the fields in the schema
        for field in schema.elementType.fields:  # Use `elementType` for ArrayType
            field_name = field.name
            field_type = field.dataType
            # If the field is a nested struct, recursively flatten it
            if isinstance(field_type, StructType):
                for nested_field in field_type.fields:
                    nested_field_name = nested_field.name
                    df = df.withColumn(
                        f"{column_name}__{field_name}__{nested_field_name}",
                        col(f"{column_name}.{field_name}.{nested_field_name}")
                    )
            else:
                # If the field is not nested, extract it directly
                df = df.withColumn(f"{column_name}__{field_name}", col(f"{column_name}.{field_name}"))
        # Drop the original JSON column
        df = df.drop(column_name)
    except Exception as error:
        print(f"Error flattening column {column_name}: {error}")
    return df



card_revenue_schema = ArrayType(StructType([
StructField("end_date", StringType(), True),
StructField("1m", StructType([
    StructField("start_date", StringType(), True),
    StructField("average_monthly_amount", DoubleType(), True)
])),
StructField("3m", StructType([
    StructField("start_date", StringType(), True),
    StructField("average_monthly_amount", DoubleType(), True)
])),
StructField("12m", StructType([
    StructField("start_date", StringType(), True),
    StructField("average_monthly_amount", DoubleType(), True)
]))
]))


column_name = "card_revenue"


df = pd.read_csv(r"C:/Users/W619378/Downloads/sprints/sprint 254 - SDS Data Processing Fixing issues in staging job identified during previous deploymen/transformed_df_local.csv")

print(df.head())

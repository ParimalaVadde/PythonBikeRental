import findspark
findspark.init()

from pyspark.sql import SparkSession

# Create a SparkSession
spark = SparkSession.builder \
    .appName("PySpark Test") \
    .master("local[*]") \
    .getOrCreate()

# Print Spark version
print(f"Spark version: {spark.version}")

# Create a simple DataFrame
data = [("Java", 8000), ("Python", 10000), ("Scala", 9000)]
columns = ["Language", "Users"]
df = spark.createDataFrame(data, columns)

# Show the DataFrame
df.show()

# Stop the SparkSession
spark.stop()

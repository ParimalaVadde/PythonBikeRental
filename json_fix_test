import pandas as pd


df = pd.read_excel(r"c:\users\w619378\downloads\The J.M. Smucker Company Presale Analysis 2025-10 (15641) AP_UT_v1.xlsb",sheet_name='Details', egine = 'pyxlsb')

df_subset = df.iloc[4:20]

print(df_subset)


**************************************************************************************************************************

import pandas as pd

# Read from local path - EXACTLY like your code
df = pd.read_excel(
    r"c:\users\w619378\downloads\The J.M. Smucker Company Presale Analysis 2025-10 (15641) AP_UT_v1.xlsb",
    sheet_name='Details',
    engine='pyxlsb',
    header=4,        # 5th row as header
    usecols='A:AW'   # Columns A to AW
)

# Convert to Spark
spark_df = spark.createDataFrame(df)


***************************************************************************************************************************

import boto3
import pandas as pd
from io import BytesIO

# S3 setup
s3 = boto3.client('s3')
s3_bucket = "app-id-111597-dep-id-114116-uu-id-9x0jt94siuto"
s3_key = "pfd_scripts/pfd_staging_pvr_test/The J.M. Smucker Company Presale Analysis 2025-10 (15641) AP_UT_v1.xlsb"

# Download and read
response = s3.get_object(Bucket=s3_bucket, Key=s3_key)
file_content = response['Body'].read()

# Read XLSB - same as your local code but with BytesIO
df = pd.read_excel(
    BytesIO(file_content),
    sheet_name='Details',
    engine='pyxlsb',
    header=4,        # 5th row as header
    usecols='A:AW'   # Columns A to AW only
)

# Convert to Spark
spark_df = spark.createDataFrame(df)
